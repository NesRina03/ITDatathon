{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "566b5307",
   "metadata": {},
   "source": [
    "# Football Player Detection Challenge\n",
    "\n",
    "## Objective\n",
    "Detect all players in football field images using YOLOv8 object detection.\n",
    "\n",
    "## Results\n",
    "- Best mAP Score: 0.80000 (Private) / 0.79563 (Public)\n",
    "- Method: Multi-scale ensemble detection with confidence boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae738f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ† Football Player Detection Challenge - Professional Solution\n",
      "============================================================\n",
      "ğŸ“‚ Base directory: /home/nesrine/Desktop/ITChallenges/ITDatathon/mc-datathon-2025-players-detection\n",
      "ğŸ–¼ï¸ Training images: 1042\n",
      "ğŸ·ï¸ Training labels: 1042\n",
      "âœ… Validation images: 351\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set paths\n",
    "BASE_DIR = Path('/home/nesrine/Desktop/ITChallenges/ITDatathon/mc-datathon-2025-players-detection')\n",
    "TRAIN_IMAGES = BASE_DIR / 'train' / 'images'\n",
    "TRAIN_LABELS = BASE_DIR / 'train' / 'labels'\n",
    "VALID_IMAGES = BASE_DIR / 'valid' / 'images'\n",
    "OUTPUT_DIR = BASE_DIR / 'output'\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Football Player Detection Challenge\")\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Training images: {len(list(TRAIN_IMAGES.glob('*.jpg')))}\")\n",
    "print(f\"Training labels: {len(list(TRAIN_LABELS.glob('*.txt')))}\")\n",
    "print(f\"Validation images: {len(list(VALID_IMAGES.glob('*.jpg')))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "868eab05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Installing required packages...\n",
      "âœ… ultralytics already installed\n",
      "ğŸ“¦ Installing opencv-python...\n",
      "âœ… ultralytics already installed\n",
      "ğŸ“¦ Installing opencv-python...\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in /home/nesrine/.local/lib/python3.13/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/lib64/python3.13/site-packages (from opencv-python) (2.2.6)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in /home/nesrine/.local/lib/python3.13/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/lib64/python3.13/site-packages (from opencv-python) (2.2.6)\n",
      "âœ… opencv-python installed successfully\n",
      "âœ… opencv-python installed successfully\n",
      "âœ… albumentations already installed\n",
      "ğŸ“¦ Installing scikit-learn...\n",
      "âœ… albumentations already installed\n",
      "ğŸ“¦ Installing scikit-learn...\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/nesrine/.local/lib/python3.13/site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /usr/lib64/python3.13/site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/nesrine/.local/lib/python3.13/site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/nesrine/.local/lib/python3.13/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/nesrine/.local/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/nesrine/.local/lib/python3.13/site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /usr/lib64/python3.13/site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/nesrine/.local/lib/python3.13/site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/nesrine/.local/lib/python3.13/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/nesrine/.local/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "âœ… scikit-learn installed successfully\n",
      "ğŸ“¦ Installing pillow...\n",
      "âœ… scikit-learn installed successfully\n",
      "ğŸ“¦ Installing pillow...\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pillow in /home/nesrine/.local/lib/python3.13/site-packages (11.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pillow in /home/nesrine/.local/lib/python3.13/site-packages (11.3.0)\n",
      "âœ… pillow installed successfully\n",
      "\n",
      "ğŸ¯ All packages installed successfully!\n",
      "âœ… pillow installed successfully\n",
      "\n",
      "ğŸ¯ All packages installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install package if not already installed\"\"\"\n",
    "    try:\n",
    "        __import__(package.split('[')[0])\n",
    "        print(f\"âœ… {package} already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"ğŸ“¦ Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"âœ… {package} installed successfully\")\n",
    "\n",
    "# List of required packages\n",
    "packages = [\n",
    "    \"ultralytics\",  # YOLOv8\n",
    "    \"opencv-python\",\n",
    "    \"albumentations\",  # Advanced data augmentation\n",
    "    \"scikit-learn\",\n",
    "    \"pillow\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ”§ Installing required packages...\")\n",
    "for package in packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\nğŸ¯ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76194867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ YOLOv8 and all libraries imported successfully!\n",
      "ğŸ¤– Ultralytics version: 8.3.169\n"
     ]
    }
   ],
   "source": [
    "# Import additional libraries after installation\n",
    "from ultralytics import YOLO\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"ğŸ”¥ YOLOv8 and all libraries imported successfully!\")\n",
    "print(f\"ğŸ¤– Ultralytics version: {__import__('ultralytics').__version__}\")\n",
    "\n",
    "# Configure matplotlib for better plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "011d0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"Calculate Intersection over Union (IoU) between two boxes\"\"\"\n",
    "    x1_inter = max(box1['x1'], box2['x1'])\n",
    "    y1_inter = max(box1['y1'], box2['y1'])\n",
    "    x2_inter = min(box1['x2'], box2['x2'])\n",
    "    y2_inter = min(box1['y2'], box2['y2'])\n",
    "    \n",
    "    if x2_inter <= x1_inter or y2_inter <= y1_inter:\n",
    "        return 0.0\n",
    "    \n",
    "    inter_area = (x2_inter - x1_inter) * (y2_inter - y1_inter)\n",
    "    \n",
    "    box1_area = (box1['x2'] - box1['x1']) * (box1['y2'] - box1['y1'])\n",
    "    box2_area = (box2['x2'] - box2['x1']) * (box2['y2'] - box2['y1'])\n",
    "    \n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    \n",
    "    return inter_area / union_area if union_area > 0 else 0.0\n",
    "\n",
    "def apply_fixed_nms_to_predictions(prediction_string, iou_threshold=0.35):\n",
    "    \"\"\"Apply Non-Maximum Suppression to prediction string\"\"\"\n",
    "    if prediction_string.strip() == \"\":\n",
    "        return \"Player 0.999000 100.0 100.0 200.0 200.0\"\n",
    "    \n",
    "    predictions = prediction_string.strip().split()\n",
    "    if len(predictions) < 6:\n",
    "        return \"Player 0.999000 100.0 100.0 200.0 200.0\"\n",
    "    \n",
    "    boxes = []\n",
    "    i = 0\n",
    "    while i < len(predictions):\n",
    "        if predictions[i] == 'Player' and i + 5 < len(predictions):\n",
    "            try:\n",
    "                conf = float(predictions[i + 1])\n",
    "                x1 = float(predictions[i + 2])\n",
    "                y1 = float(predictions[i + 3])\n",
    "                x2 = float(predictions[i + 4])\n",
    "                y2 = float(predictions[i + 5])\n",
    "                boxes.append({'confidence': conf, 'x1': x1, 'y1': y1, 'x2': x2, 'y2': y2})\n",
    "                i += 6\n",
    "            except (ValueError, IndexError):\n",
    "                i += 1\n",
    "        else:\n",
    "            i += 1\n",
    "    \n",
    "    if not boxes:\n",
    "        return \"Player 0.999000 100.0 100.0 200.0 200.0\"\n",
    "    \n",
    "    boxes.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "    \n",
    "    keep = []\n",
    "    for box in boxes:\n",
    "        should_keep = True\n",
    "        for kept_box in keep:\n",
    "            if calculate_iou(box, kept_box) > iou_threshold:\n",
    "                should_keep = False\n",
    "                break\n",
    "        if should_keep:\n",
    "            keep.append(box)\n",
    "    \n",
    "    result_parts = []\n",
    "    for box in keep:\n",
    "        result_parts.append(f\"Player {box['confidence']:.6f} {box['x1']:.1f} {box['y1']:.1f} {box['x2']:.1f} {box['y2']:.1f}\")\n",
    "    \n",
    "    return ' '.join(result_parts) if result_parts else \"Player 0.999000 100.0 100.0 200.0 200.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0a7d50",
   "metadata": {},
   "source": [
    "## ğŸ” Data Analysis & Exploration\n",
    "\n",
    "Let's analyze our dataset to understand the distribution of players, image characteristics, and annotation quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c55f0ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Analyzing training dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing labels: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1042/1042 [00:00<00:00, 6658.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¯ Training Dataset Statistics:\n",
      "ğŸ“ Total images: 1042\n",
      "ğŸ‘¥ Total players: 23753\n",
      "ğŸ“ˆ Average players per image: 22.80\n",
      "ğŸ“Š Min players per image: 7\n",
      "ğŸ“Š Max players per image: 25\n",
      "ğŸ“ Average bbox area: 0.0009\n",
      "ğŸ“ Average aspect ratio: 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def analyze_yolo_labels(labels_dir):\n",
    "    \"\"\"Analyze YOLO label files and return statistics\"\"\"\n",
    "    stats = {\n",
    "        'total_images': 0,\n",
    "        'total_players': 0,\n",
    "        'players_per_image': [],\n",
    "        'bbox_areas': [],\n",
    "        'bbox_aspect_ratios': [],\n",
    "        'center_x': [],\n",
    "        'center_y': []\n",
    "    }\n",
    "    \n",
    "    label_files = list(Path(labels_dir).glob('*.txt'))\n",
    "    stats['total_images'] = len(label_files)\n",
    "    \n",
    "    for label_file in tqdm(label_files, desc=\"Analyzing labels\"):\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        image_player_count = 0\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 5:\n",
    "                class_id, x_center, y_center, width, height = map(float, parts[:5])\n",
    "                if class_id == 2:  # Player class\n",
    "                    image_player_count += 1\n",
    "                    stats['total_players'] += 1\n",
    "                    \n",
    "                    # Calculate area and aspect ratio\n",
    "                    area = width * height\n",
    "                    aspect_ratio = width / height if height > 0 else 0\n",
    "                    \n",
    "                    stats['bbox_areas'].append(area)\n",
    "                    stats['bbox_aspect_ratios'].append(aspect_ratio)\n",
    "                    stats['center_x'].append(x_center)\n",
    "                    stats['center_y'].append(y_center)\n",
    "        \n",
    "        stats['players_per_image'].append(image_player_count)\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Analyze training data\n",
    "print(\"ğŸ“Š Analyzing training dataset...\")\n",
    "train_stats = analyze_yolo_labels(TRAIN_LABELS)\n",
    "\n",
    "print(f\"\\nğŸ¯ Training Dataset Statistics:\")\n",
    "print(f\"ğŸ“ Total images: {train_stats['total_images']}\")\n",
    "print(f\"ğŸ‘¥ Total players: {train_stats['total_players']}\")\n",
    "print(f\"ğŸ“ˆ Average players per image: {np.mean(train_stats['players_per_image']):.2f}\")\n",
    "print(f\"ğŸ“Š Min players per image: {min(train_stats['players_per_image'])}\")\n",
    "print(f\"ğŸ“Š Max players per image: {max(train_stats['players_per_image'])}\")\n",
    "print(f\"ğŸ“ Average bbox area: {np.mean(train_stats['bbox_areas']):.4f}\")\n",
    "print(f\"ğŸ“ Average aspect ratio: {np.mean(train_stats['bbox_aspect_ratios']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d202dca7",
   "metadata": {},
   "source": [
    "## Final Solution - Multi-Scale Ensemble Detection\n",
    "\n",
    "The following implementation achieved the best results:\n",
    "- Private mAP: 0.80000\n",
    "- Public mAP: 0.79563\n",
    "\n",
    "Key techniques:\n",
    "1. Multi-scale detection (576, 640, 704px)\n",
    "2. Confidence boosting based on detection ranking\n",
    "3. Ensemble NMS for duplicate removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "413e555d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset: 351 images\n",
      "Running multi-scale ensemble detection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 351/351 [04:21<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying final NMS...\n",
      "Final submission saved: /home/nesrine/Desktop/ITChallenges/ITDatathon/mc-datathon-2025-players-detection/output/FINAL_BEST_submission.csv\n",
      "Shape: (351, 2)\n",
      "Total predictions: 6627\n",
      "Average per image: 18.88\n",
      "\\nSample predictions:\n",
      "1: Player 0.906982 460.2 361.8 472.3 398.6 Player 0.890614 270.3 246.4 281.7 274.3 ...\n",
      "2: Player 0.910835 320.3 225.4 339.8 268.1 Player 0.897034 535.2 200.3 548.4 242.8 ...\n",
      "3: Player 0.919530 375.1 276.8 391.2 325.6 Player 0.895833 370.3 210.3 382.9 251.8 ...\n",
      "\\nSubmission ready for competition.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def multi_scale_ensemble_detection(test_df):\n",
    "    \"\"\"\n",
    "    Final implementation: Multi-scale ensemble detection\n",
    "    Achieved: 0.80000 Private mAP / 0.79563 Public mAP\n",
    "    \"\"\"\n",
    "    print(\"Running multi-scale ensemble detection...\")\n",
    "    \n",
    "    model = YOLO('yolov8n.pt')\n",
    "    scales = [576, 640, 704]\n",
    "    confidence_threshold = 0.25\n",
    "    \n",
    "    # Find test images\n",
    "    test_images_base = BASE_DIR / 'valid' / 'images'\n",
    "    if not test_images_base.exists():\n",
    "        test_images_base = BASE_DIR / 'train' / 'images'\n",
    "    \n",
    "    predictions_data = []\n",
    "    \n",
    "    for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Processing\"):\n",
    "        image_id = row['image_id']\n",
    "        \n",
    "        # Find image file\n",
    "        img_path = None\n",
    "        potential_files = list(test_images_base.glob(f\"*{image_id}*\"))\n",
    "        if potential_files:\n",
    "            img_path = potential_files[0]\n",
    "        \n",
    "        if img_path is None:\n",
    "            predictions_data.append({\n",
    "                'image_id': image_id,\n",
    "                'prediction_string': \"Player 1.000000 100.0 100.0 200.0 200.0\"\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Multi-scale detection\n",
    "        all_predictions = []\n",
    "        \n",
    "        for scale in scales:\n",
    "            try:\n",
    "                results = model(str(img_path), imgsz=scale, conf=confidence_threshold, verbose=False)\n",
    "                \n",
    "                for result in results:\n",
    "                    boxes = result.boxes\n",
    "                    if boxes is not None:\n",
    "                        for box in boxes:\n",
    "                            cls = int(box.cls[0].cpu().numpy())\n",
    "                            conf = float(box.conf[0].cpu().numpy())\n",
    "                            \n",
    "                            if cls == 0 and conf >= confidence_threshold:\n",
    "                                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                                \n",
    "                                all_predictions.append({\n",
    "                                    'confidence': conf,\n",
    "                                    'x1': float(x1), 'y1': float(y1),\n",
    "                                    'x2': float(x2), 'y2': float(y2)\n",
    "                                })\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        # Ensemble NMS and confidence boosting\n",
    "        if all_predictions:\n",
    "            all_predictions = sorted(all_predictions, key=lambda x: x['confidence'], reverse=True)\n",
    "            \n",
    "            final_predictions = []\n",
    "            for pred in all_predictions:\n",
    "                keep = True\n",
    "                for existing in final_predictions:\n",
    "                    iou = calculate_iou(pred, existing)\n",
    "                    if iou > 0.3:\n",
    "                        if pred['confidence'] <= existing['confidence']:\n",
    "                            keep = False\n",
    "                            break\n",
    "                        else:\n",
    "                            final_predictions.remove(existing)\n",
    "                            break\n",
    "                \n",
    "                if keep:\n",
    "                    final_predictions.append(pred)\n",
    "            \n",
    "            final_predictions = final_predictions[:25]\n",
    "            \n",
    "            # Confidence boosting\n",
    "            pred_strings = []\n",
    "            for i, pred in enumerate(final_predictions):\n",
    "                boost = max(0.8, pred['confidence'] + (0.2 * (len(final_predictions) - i) / len(final_predictions)))\n",
    "                boost = min(1.0, boost)\n",
    "                \n",
    "                pred_str = f\"Player {boost:.6f} {pred['x1']:.1f} {pred['y1']:.1f} {pred['x2']:.1f} {pred['y2']:.1f}\"\n",
    "                pred_strings.append(pred_str)\n",
    "            \n",
    "            prediction_string = ' '.join(pred_strings)\n",
    "        else:\n",
    "            prediction_string = \"Player 0.999000 100.0 100.0 200.0 200.0\"\n",
    "        \n",
    "        predictions_data.append({\n",
    "            'image_id': image_id,\n",
    "            'prediction_string': prediction_string\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(predictions_data)\n",
    "\n",
    "# Load test data and generate final submission\n",
    "test_df = pd.read_csv(BASE_DIR / 'images_test.csv')\n",
    "print(f\"Test dataset: {len(test_df)} images\")\n",
    "\n",
    "# Generate predictions\n",
    "final_submission = multi_scale_ensemble_detection(test_df)\n",
    "\n",
    "# Apply NMS\n",
    "print(\"Applying final NMS...\")\n",
    "final_submission['prediction_string'] = final_submission['prediction_string'].apply(\n",
    "    lambda x: apply_fixed_nms_to_predictions(x, iou_threshold=0.35)\n",
    ")\n",
    "\n",
    "# Save final submission\n",
    "final_path = OUTPUT_DIR / 'FINAL_BEST_submission.csv'\n",
    "final_submission.to_csv(final_path, index=False)\n",
    "\n",
    "print(f\"Final submission saved: {final_path}\")\n",
    "print(f\"Shape: {final_submission.shape}\")\n",
    "\n",
    "# Analysis\n",
    "total_preds = final_submission['prediction_string'].apply(lambda x: x.count('Player')).sum()\n",
    "avg_preds = total_preds / len(final_submission)\n",
    "print(f\"Total predictions: {total_preds}\")\n",
    "print(f\"Average per image: {avg_preds:.2f}\")\n",
    "\n",
    "print(\"\\\\nSample predictions:\")\n",
    "for i in range(3):\n",
    "    pred = final_submission.iloc[i]['prediction_string']\n",
    "    print(f\"{i+1}: {pred[:80]}...\")\n",
    "\n",
    "print(\"\\\\nSubmission ready for competition.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
